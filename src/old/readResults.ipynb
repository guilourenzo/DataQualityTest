{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT LIBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import pymongo as mongo\n",
    "from itertools import compress\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configparser import ConfigParser\n",
    "\n",
    "CONFIG = ConfigParser()\n",
    "CONFIG.read('../config/dq.ini')\n",
    "MONGO_SERVER = CONFIG[\"MONGO_SERVER\"]\n",
    "\n",
    "HOST = MONGO_SERVER['MONGO_HOST']\n",
    "PORT = int(MONGO_SERVER['MONGO_PORT'])\n",
    "DB = MONGO_SERVER['MONGO_DB']\n",
    "COL = MONGO_SERVER['MONGO_COLLECTIONS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = mongo.MongoClient(HOST, PORT)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINE FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openValidation(jsonPath: str) -> dict:\n",
    "    try:\n",
    "        with open(jsonPath, 'r') as result_json:\n",
    "            print(f'FILE OPENED WITH SUCCESS !')\n",
    "            return json.loads(result_json.read())\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'ERROR - READING VALIDATION FILE - {jsonPath}: \\n {e}')\n",
    "        raise\n",
    "\n",
    "def formatResults(validationJSON: dict) -> dict:\n",
    "    formatedResults = ({\n",
    "\n",
    "        'expectation_suite_name' :  validationJSON['meta'].get('expectation_suite_name', None),\n",
    "        'checkpoint_name' : validationJSON['meta'].get('checkpoint_name', None),\n",
    "        'data_asset_name' : validationJSON['meta']['active_batch_definition'].get('data_asset_name', None),\n",
    "        'path_file' :  validationJSON['meta']['batch_spec'].get('path', None),\n",
    "        'run_name' : validationJSON['meta']['run_id'].get('run_name', None),\n",
    "        'run_time' : validationJSON['meta']['run_id'].get('run_time', None),\n",
    "\n",
    "        'results' : [{\n",
    "                'rule' : validationJSON['results'][expect]['expectation_config'].get('expectation_type', None),\n",
    "                'rule_detail' : validationJSON['results'][expect]['expectation_config'].get('kwargs', None),\n",
    "\n",
    "                'rows_evaluated' : validationJSON['results'][expect]['result'].get('element_count', None),\n",
    "                'unexpected_count' : validationJSON['results'][expect]['result'].get('unexpected_count', None),\n",
    "                'unexpected_percent' : validationJSON['results'][expect]['result'].get('unexpected_percent', None),\n",
    "                'rule_result': validationJSON['results'][expect].get('success', None)\n",
    "                } for expect in range(len(validationJSON['results']))] ,\n",
    "\n",
    "        'statistics': {\n",
    "            'evaluated_expectations': validationJSON['statistics'].get('evaluated_expectations', None),\n",
    "            'success_percent': validationJSON['statistics'].get('success_percent', None),\n",
    "            'successful_expectations': validationJSON['statistics'].get('successful_expectations', None),\n",
    "            'unsuccessful_expectations': validationJSON['statistics'].get('unsuccessful_expectations', None),\n",
    "        },\n",
    "\n",
    "        'expectation_result': validationJSON['success']\n",
    "    })\n",
    "\n",
    "    for i in range(len(formatedResults['results'])):\n",
    "            del formatedResults['results'][i]['rule_detail']['batch_id']\n",
    "    \n",
    "    return formatedResults\n",
    "\n",
    "def registerValidation(mongoClient, databaseName: str, collectionName: str, formatedResults: dict):\n",
    "    try:\n",
    "        db = mongoClient.get_database(databaseName)\n",
    "    except Exception as e:\n",
    "        print(f'ERROR - MONGO CONNECITON - GET DATABASE: \\n {e}')\n",
    "\n",
    "    try:\n",
    "        dbColl = db.get_collection(collectionName)\n",
    "    except Exception as e:\n",
    "        print(f'ERROR - MONGO CONNECITON - GET COLLECTION: \\n {e}')\n",
    "    \n",
    "    try:\n",
    "        dbColl.insert_one(formatedResults)\n",
    "    except Exception as e:\n",
    "        print(f'ERROR - MONGO CONNECITON - SAVING RESULTS: \\n {e}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN THE PROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = glob.glob('../output/validations/DataQuality/**/*.json', recursive=True)\n",
    "latest_file = max(val, key=os.path.getctime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE OPENED WITH SUCCESS !\n"
     ]
    }
   ],
   "source": [
    "validationJSON = openValidation(latest_file)\n",
    "\n",
    "formatedResults = formatResults(validationJSON)\n",
    "\n",
    "registerValidation(client, DB, COL, formatedResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE OPENED WITH SUCCESS !\n",
      "FILE OPENED WITH SUCCESS !\n",
      "FILE OPENED WITH SUCCESS !\n",
      "FILE OPENED WITH SUCCESS !\n",
      "FILE OPENED WITH SUCCESS !\n",
      "FILE OPENED WITH SUCCESS !\n",
      "FILE OPENED WITH SUCCESS !\n",
      "FILE OPENED WITH SUCCESS !\n",
      "FILE OPENED WITH SUCCESS !\n",
      "FILE OPENED WITH SUCCESS !\n"
     ]
    }
   ],
   "source": [
    "for validation in glob.iglob('../output/validations/DataQuality/**/*.json', recursive=True):\n",
    "    validationJSON = openValidation(validation)\n",
    "\n",
    "    formatedResults = formatResults(validationJSON)\n",
    "    \n",
    "    registerValidation(client, 'greatExpectations', 'expectationsResults', formatedResults)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('result.json', 'r') as result_json:\n",
    "    result = json.loads(result_json.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "geResult = ({\n",
    "\n",
    "        'expectation_suite_name' :  result['meta'].get('expectation_suite_name', None),\n",
    "        'checkpoint_name' : result['meta'].get('checkpoint_name', None),\n",
    "        'data_asset_name' : result['meta']['active_batch_definition'].get('data_asset_name', None),\n",
    "        'path_file' :  result['meta']['batch_spec'].get('path', None),\n",
    "        'run_name' : result['meta']['run_id'].get('run_name', None),\n",
    "        'run_time' : result['meta']['run_id'].get('run_time', None),\n",
    "\n",
    "        'results' : [{\n",
    "                'rule' : result['results'][expect]['expectation_config'].get('expectation_type', None),\n",
    "                'rule_detail' : result['results'][expect]['expectation_config'].get('kwargs', None),\n",
    "\n",
    "                'rows_evaluated' : result['results'][expect]['result'].get('element_count', None),\n",
    "                'unexpected_count' : result['results'][expect]['result'].get('unexpected_count', None),\n",
    "                'unexpected_percent' : result['results'][expect]['result'].get('unexpected_percent', None),\n",
    "                'rule_result': result['results'][expect].get('success', None)\n",
    "                } for expect in range(len(result['results']))] ,\n",
    "\n",
    "        'statistics': {\n",
    "            'evaluated_expectations': result['statistics'].get('evaluated_expectations', None),\n",
    "            'success_percent': result['statistics'].get('success_percent', None),\n",
    "            'successful_expectations': result['statistics'].get('successful_expectations', None),\n",
    "            'unsuccessful_expectations': result['statistics'].get('unsuccessful_expectations', None),\n",
    "        },\n",
    "\n",
    "        'expectation_result': result['success']\n",
    "})\n",
    "\n",
    "for i in range(len(geResult['results'])):\n",
    "        del geResult['results'][i]['rule_detail']['batch_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = client.get_database('greatExpectations')\n",
    "dbColl = db.get_collection('expectations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertOneResult at 0x20f2b898e40>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbColl.insert_one(geResult)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
