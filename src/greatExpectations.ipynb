{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT LIBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import great_expectations as gx\n",
    "from great_expectations.data_context.types.base import DataContextConfig, DatasourceConfig, FilesystemStoreBackendDefaults\n",
    "from great_expectations.core.batch import BatchRequest, RuntimeBatchRequest\n",
    "\n",
    "from ruamel import yaml\n",
    "\n",
    "root_directory = '/development/wsl/DataQualityTest/config/quality/'\n",
    "data_directory = '/development/wsl/DataQualityTest/data/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONFIGURATION PROCESS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE DATA CONTEXT CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSourceGE = DataContextConfig(\n",
    "    store_backend_defaults=FilesystemStoreBackendDefaults(\n",
    "        root_directory=root_directory\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE DATA CONTEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = gx.get_context(project_config=dataSourceGE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE DATA SOURCE CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasource_config = {\n",
    "    \"name\": \"pandasDataSource\",\n",
    "    \"class_name\": \"Datasource\",\n",
    "    \"module_name\": \"great_expectations.datasource\",\n",
    "    \"execution_engine\": {\n",
    "        \"module_name\": \"great_expectations.execution_engine\",\n",
    "        \"class_name\": \"PandasExecutionEngine\",\n",
    "    },\n",
    "    \"data_connectors\": {\n",
    "        \"runtimeConnector\": {\n",
    "            \"class_name\": \"RuntimeDataConnector\",\n",
    "            \"module_name\": \"great_expectations.datasource.data_connector\",\n",
    "            \"batch_identifiers\": [\"default_identifier_name\"],\n",
    "        },\n",
    "        \"folderConnector\": {\n",
    "            \"class_name\": \"InferredAssetFilesystemDataConnector\",\n",
    "            \"base_directory\": data_directory,\n",
    "            \"default_regex\": {\"group_names\": [\"data_asset_name\"], \"pattern\": \"(.*)\\.csv$\"},\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST DATA SOURCE CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to instantiate class from config...\n",
      "\tInstantiating as a Datasource, since class_name is Datasource\n",
      "\tSuccessfully instantiated Datasource\n",
      "\n",
      "\n",
      "ExecutionEngine class name: PandasExecutionEngine\n",
      "Data Connectors:\n",
      "\tfolderConnector : InferredAssetFilesystemDataConnector\n",
      "\n",
      "\tAvailable data_asset_names (1 of 1):\n",
      "\t\tLooks_vs_Personality (1 of 1): ['Looks_vs_Personality.csv']\n",
      "\n",
      "\tUnmatched data_references (1 of 1):['README.md']\n",
      "\n",
      "\truntimeConnector:RuntimeDataConnector\n",
      "\n",
      "\tAvailable data_asset_names (0 of 0):\n",
      "\t\tNote : RuntimeDataConnector will not have data_asset_names until they are passed in through RuntimeBatchRequest\n",
      "\n",
      "\tUnmatched data_references (0 of 0): []\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<great_expectations.datasource.new_datasource.Datasource at 0x24b117abbb0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.test_yaml_config(yaml.dump(datasource_config))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADD DATA SOURCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<great_expectations.datasource.new_datasource.Datasource at 0x24b117d26d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.add_datasource(**datasource_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHECK DATA SOURCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'execution_engine': {'class_name': 'PandasExecutionEngine',\n",
       "   'module_name': 'great_expectations.execution_engine'},\n",
       "  'class_name': 'Datasource',\n",
       "  'name': 'pandasDataSource',\n",
       "  'module_name': 'great_expectations.datasource',\n",
       "  'data_connectors': {'runtimeConnector': {'class_name': 'RuntimeDataConnector',\n",
       "    'batch_identifiers': ['default_identifier_name'],\n",
       "    'module_name': 'great_expectations.datasource.data_connector'},\n",
       "   'folderConnector': {'default_regex': {'group_names': ['data_asset_name'],\n",
       "     'pattern': '(.*)\\\\.csv$'},\n",
       "    'class_name': 'InferredAssetFilesystemDataConnector',\n",
       "    'module_name': 'great_expectations.datasource.data_connector',\n",
       "    'base_directory': '/development/wsl/DataQualityTest/data/'}}}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.list_datasources()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VALIDATION PROCESS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE BATCH REQUEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_request = BatchRequest(\n",
    "    datasource_name=context.list_datasources()[0][\"name\"],\n",
    "    data_connector_name=\"folderConnector\",\n",
    "    data_asset_name=context.get_available_data_asset_names()['pandasDataSource']['folderConnector'][0],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"datasource_name\": \"pandasDataSource\",\n",
       "  \"data_connector_name\": \"folderConnector\",\n",
       "  \"data_asset_name\": \"Looks_vs_Personality\"\n",
       "}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_request"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE EXPECTATION SUITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"data_asset_type\": null,\n",
       "  \"expectations\": [],\n",
       "  \"expectation_suite_name\": \"DataQuality\",\n",
       "  \"meta\": {\n",
       "    \"great_expectations_version\": \"0.15.43\"\n",
       "  },\n",
       "  \"ge_cloud_id\": null\n",
       "}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expectation_suite_name = 'DataQuality'\n",
    "context.create_expectation_suite(\n",
    "    expectation_suite_name=expectation_suite_name, overwrite_existing=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE VALIDATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9b36fdfed354997aca94978f97ae870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unweighted_Sample  Weighted_Sample               Question Nationality  \\\n",
      "0                454              530  They are good looking    American   \n",
      "1                454              530  They are good looking    American   \n",
      "\n",
      "  Gender    Rank (text)  Rank (number)  Percentage  \n",
      "0    Men   Ranked first              1       18.00  \n",
      "1    Men  Ranked second              2        0.13  \n"
     ]
    }
   ],
   "source": [
    "validator = context.get_validator(\n",
    "    batch_request=batch_request, expectation_suite_name=expectation_suite_name\n",
    ")\n",
    "print(validator.head(2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEFINE RULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d9aec3a208148edb160b68b17f276ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"result\": {\n",
       "    \"element_count\": 1440,\n",
       "    \"unexpected_count\": 3,\n",
       "    \"unexpected_percent\": 0.20833333333333334,\n",
       "    \"partial_unexpected_list\": [\n",
       "      null,\n",
       "      null,\n",
       "      null\n",
       "    ]\n",
       "  },\n",
       "  \"exception_info\": {\n",
       "    \"raised_exception\": false,\n",
       "    \"exception_traceback\": null,\n",
       "    \"exception_message\": null\n",
       "  },\n",
       "  \"meta\": {},\n",
       "  \"success\": false\n",
       "}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validator.expect_column_values_to_not_be_null(column='Question')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd0220e54e304d85a5af7dc91f6b90f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"result\": {\n",
       "    \"element_count\": 1440,\n",
       "    \"unexpected_count\": 2,\n",
       "    \"unexpected_percent\": 0.1388888888888889,\n",
       "    \"partial_unexpected_list\": [\n",
       "      18.0,\n",
       "      8.0\n",
       "    ],\n",
       "    \"missing_count\": 0,\n",
       "    \"missing_percent\": 0.0,\n",
       "    \"unexpected_percent_total\": 0.1388888888888889,\n",
       "    \"unexpected_percent_nonmissing\": 0.1388888888888889\n",
       "  },\n",
       "  \"exception_info\": {\n",
       "    \"raised_exception\": false,\n",
       "    \"exception_traceback\": null,\n",
       "    \"exception_message\": null\n",
       "  },\n",
       "  \"meta\": {},\n",
       "  \"success\": false\n",
       "}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validator.expect_column_values_to_be_between(\n",
    "    column=\"Percentage\", min_value=0, max_value=1\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAVE RULES ON VALIDATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "validator.save_expectation_suite(discard_failed_expectations=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE CHECKPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_checkpoint_name = \"dataQuality_Check\"\n",
    "\n",
    "checkpoint_config = {\n",
    "    \"name\": my_checkpoint_name,\n",
    "    \"config_version\": 1.0,\n",
    "    \"class_name\": \"SimpleCheckpoint\",\n",
    "    \"run_name_template\": \"qualityCheck_%d-%m-%Y_%H-%M\",\n",
    "    \"validations\": [\n",
    "        {\n",
    "            \"batch_request\": batch_request,\n",
    "            \"expectation_suite_name\": expectation_suite_name,\n",
    "        }\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST CHECKPOINT CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to instantiate class from config...\n",
      "\tInstantiating as a SimpleCheckpoint, since class_name is SimpleCheckpoint\n",
      "\tSuccessfully instantiated SimpleCheckpoint\n",
      "\n",
      "\n",
      "Checkpoint class name: SimpleCheckpoint\n"
     ]
    }
   ],
   "source": [
    "my_checkpoint = context.test_yaml_config(yaml.dump(checkpoint_config))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADD CHECKPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"action_list\": [\n",
       "    {\n",
       "      \"name\": \"store_validation_result\",\n",
       "      \"action\": {\n",
       "        \"class_name\": \"StoreValidationResultAction\"\n",
       "      }\n",
       "    },\n",
       "    {\n",
       "      \"name\": \"store_evaluation_params\",\n",
       "      \"action\": {\n",
       "        \"class_name\": \"StoreEvaluationParametersAction\"\n",
       "      }\n",
       "    },\n",
       "    {\n",
       "      \"name\": \"update_data_docs\",\n",
       "      \"action\": {\n",
       "        \"class_name\": \"UpdateDataDocsAction\",\n",
       "        \"site_names\": []\n",
       "      }\n",
       "    }\n",
       "  ],\n",
       "  \"batch_request\": {},\n",
       "  \"class_name\": \"Checkpoint\",\n",
       "  \"config_version\": 1.0,\n",
       "  \"evaluation_parameters\": {},\n",
       "  \"module_name\": \"great_expectations.checkpoint\",\n",
       "  \"name\": \"dataQuality_Check\",\n",
       "  \"profilers\": [],\n",
       "  \"run_name_template\": \"qualityCheck_%d-%m-%Y_%H-%M\",\n",
       "  \"runtime_configuration\": {},\n",
       "  \"validations\": [\n",
       "    {\n",
       "      \"batch_request\": {\n",
       "        \"datasource_name\": \"pandasDataSource\",\n",
       "        \"data_connector_name\": \"folderConnector\",\n",
       "        \"data_asset_name\": \"Looks_vs_Personality\"\n",
       "      },\n",
       "      \"expectation_suite_name\": \"DataQuality\"\n",
       "    }\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.add_checkpoint(**checkpoint_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN CHECKPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca1e9bca4b2f4bdbb7809c4522d2df87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint_result = context.run_checkpoint(\n",
    "    checkpoint_name=my_checkpoint_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
